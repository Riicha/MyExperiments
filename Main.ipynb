{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Analysis of the Influencers:\n",
    "# 2. Sentiment Analysis of the Influencers: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TM -Import the Dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import seaborn as sns\n",
    "from os import path, makedirs # fetch path and makedirs function from os file\n",
    "import csv # fetch csv file\n",
    "from glob import glob # fetching glob function only from the glob lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TM -Import keys from the config file\n",
    "# from config import consumer_key, consumer_secret, access_token, access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TM - Twitter API Keys\n",
    "# consumer_key = 'Your Key'\n",
    "# consumer_secret = 'Your Key'\n",
    "# access_token = 'Your Key'\n",
    "# access_token_secret = 'Your Key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter TheDataDash1 API Keys\n",
    "consumer_key = 'HHEIT7aJjF5SjlhQQ7w40rcZb'\n",
    "consumer_secret = 'RK0DJHrmwBdSEEs096gQoQBmElEBrtVeRkffveiDLq6RiesUar'\n",
    "access_token = '1015366295838253057-NXFWxcz1HcCog8CkLhRgN2JV44PQBP'\n",
    "access_token_secret = 'qMAM1dplnr3vIOWlw2D0ox39R2cgn2S4VPybZadg1bfxN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TM - Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TM - Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TM - Load and read csv file containing the details of the Influencers \n",
    "influencer_data_load = \"RawData/SentimentInfluencerInputData.csv\"\n",
    "influencer_data_read = pd.read_csv(influencer_data_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Team version merged.\n",
    "# TM - for index, row in Influencers_DF.iterrows():\n",
    "Data_Influencers_DF = influencer_data_read\n",
    "Not_Found = 0\n",
    "\n",
    "#  TM - Define variable for holding tweets for influencer\n",
    "\n",
    "all_tweet_listing = []\n",
    "\n",
    "print(\"-----------Start extraction!!!-----------\")\n",
    "\n",
    "for index, row in Data_Influencers_DF.iterrows():\n",
    "    target_user = row[\"Twitter_Handle\"]\n",
    "    Genre =  row[\"Genre\"]\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # TM -  retrieve top 200 tweets for influencer\n",
    "        \n",
    "        public_tweets = api.user_timeline(target_user, count=200, result_type=\"recent\")\n",
    "\n",
    "        # TM -  write to all_tweet_listing\n",
    "\n",
    "        for tweet in public_tweets:\n",
    "            \n",
    "            Date = datetime.strptime(tweet['created_at'],'%a %b %d %H:%M:%S %z %Y').strftime('%m/%d/%Y')\n",
    "\n",
    "            all_tweet_listing.append({\"Influencer\":target_user,\n",
    "                               \"Date\": Date,\n",
    "                               \"Genre\":Genre,\n",
    "                               \"Tweet\":tweet[\"text\"],\n",
    "                               \"Retweet_Count\":tweet[\"retweet_count\"]})\n",
    "    \n",
    "        user_account = api.get_user(target_user)\n",
    "        user_geo_enabled = user_account[\"geo_enabled\"]\n",
    "        if (user_geo_enabled == True):\n",
    "            Data_Influencers_DF.at[index, \"Loc\"] = user_account[\"location\"]\n",
    "        else:\n",
    "            Data_Influencers_DF.at[index, \"Loc\"] = 'NA'\n",
    "\n",
    "        if (user_account[\"lang\"] == 'en'):\n",
    "            Data_Influencers_DF.at[index, \"Lang\"] = 'Eng'\n",
    "        else:\n",
    "            Data_Influencers_DF.at[index, \"Lang\"] = 'NA'\n",
    "        \n",
    "        Data_Influencers_DF.at[index, \"Created On\"] = datetime.strptime(user_account['created_at'],'%a %b %d %H:%M:%S %z %Y').strftime('%m/%d/%Y')\n",
    "        \n",
    "        Data_Influencers_DF.at[index, \"Age Of Account\"] = (datetime.now(timezone.utc) - datetime.strptime(user_account['created_at'],'%a %b %d %H:%M:%S %z %Y')).days\n",
    "        \n",
    "        \n",
    "       #  TM -  Data_Influencers_DF.at[index, \"Real Name\"] = user_real_name\n",
    "        Data_Influencers_DF.at[index, \"Tweets\"] = user_account[\"statuses_count\"]\n",
    "        Data_Influencers_DF.at[index, \"Followers\"] = user_account[\"followers_count\"]\n",
    "        Data_Influencers_DF.at[index, \"Following\"] = user_account[\"friends_count\"]\n",
    "        Data_Influencers_DF.at[index, \"Favorites Count\"] = user_account[\"favourites_count\"]\n",
    "        \n",
    "              \n",
    "    \n",
    "    except tweepy.TweepError as e:\n",
    "        Not_Found = Not_Found + 1\n",
    "        print(f\"exception for {row['Twitter_Handle']}: {e}\")\n",
    "\n",
    "print(\"----------- Extraction Complete !!!-----------\")        \n",
    "print(Not_Found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TM - translate dict to a dataframe\n",
    "tweet_listing_pd = pd.DataFrame.from_dict(all_tweet_listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TM - stats for tweet listing for influencers. PLEASE DON'T REMOVE. Required to quantify digital footprint!\n",
    "tweet_listing_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TM - top 1000 key words from Influencer tweets#SS -to \n",
    "\n",
    "Top_1000 = pd.Series(' '.join(tweet_listing_pd['Tweet']).lower().split()).value_counts()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TM - Saving the out put into a csv file\n",
    "Top_1000.to_csv(\"RawData/Top_1000_keywords.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TM -  Write to CSV for analysis\n",
    "tweet_listing_pd.to_csv(\"RawData/TweetListings.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SS - String type casting for Tweets column\n",
    "\n",
    "tweet_listing_pd.Tweet = tweet_listing_pd.Tweet.map(''.join).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SS - define target tags for social and entertainment\n",
    "\n",
    "social_target_tags = [\"#FamiliesBelongTogetherMarch\",\"#gun\",\"gun\",\"shooting\",\"gun-control\",\"election\",\"#metoo\",\"metoo\",\"FamiliesBelongTogetherMarch\",\"PrideMonth\",\"#PrideMonth\",\"FamiliesBelongTogether\",\"ChildreninCages\",\"UniteTheFamilies\",\"WeCare\"]\n",
    "\n",
    "entertainment_target_tags = [\"#SocialMediaDay\",\"SocialMediaDay\",\"WorldCup\",\"#WorldCup\",\"#fifa\",\"fifa\", \"#worldcup2018russia\",\"#PostASongLyricYouLove\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SS - function to match tweet with tags\n",
    "\n",
    "def matcher_tweet(x):\n",
    "    for i in social_target_tags:\n",
    "        if i.lower() in x.lower():\n",
    "            return(\"Social\")\n",
    "        \n",
    "    for j in entertainment_target_tags:\n",
    "        if j.lower() in x.lower():\n",
    "            return(\"Entertainment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SS - Add new column to tweet_listing_pd to capture Category - Social vs Entertainment\n",
    "\n",
    "tweet_listing_pd['Tweet_Category'] = tweet_listing_pd['Tweet'].apply(matcher_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SS - Analysis of tweet_listing_pd\n",
    "tweet_listing_pd_sorted = tweet_listing_pd.sort_values(\"Retweet_Count\",ascending=False)\n",
    "\n",
    "tweet_listing_pd_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SS - Genre vs Catgegory\n",
    "tweet_listing_pd_sorted_Summary = tweet_listing_pd_sorted.groupby([\"Tweet_Category\",\"Genre\"],as_index=False).count()\n",
    "tweet_listing_DF = tweet_listing_pd_sorted_Summary[[\"Tweet_Category\",\"Genre\",\"Tweet\"]]\n",
    "tweet_listing_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SS  - Plot Tweet Category vs Number of Tweets\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "sns.factorplot(x='Tweet_Category', y='Tweet', hue='Genre', data=tweet_listing_DF, kind='bar')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TM - Remove the records of people who have not tweeted at all\n",
    "Data_Influencers_DF = Data_Influencers_DF[Data_Influencers_DF['Tweets']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TM -  Remove missing values.\n",
    "Data_Influencers_DF.dropna()\n",
    "\n",
    "Data_Influencers_DF.to_csv('OutPut/Influencer_Analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TM - Print the DF\n",
    "Data_Influencers_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#   TM - Grouped on Genre \n",
    "#   TM - Data_Influencers_DF.is_copy = False. The .copy() helps to get rid of warning.\n",
    "\n",
    "Data_Influencers_DF['Average Tweets'] = Data_Influencers_DF['Tweets'].copy()\n",
    "Data_Influencers_DF['Count'] = 0\n",
    "\n",
    "\n",
    "AggregatedGenre = Data_Influencers_DF.groupby([\"Genre\"]).agg({'Genre': 'min', 'Tweets': 'sum', 'Followers': 'sum','Average Tweets':'mean','Age Of Account':'mean','Count':'size'})\n",
    "\n",
    "AggregatedGenre.sort_values(['Followers'], ascending =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   TM - Sorting on Average Tweets and grouped on Genere\n",
    "AggregatedGenre.sort_values(['Average Tweets'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " ## TM - whole cell\n",
    "# Labels for the sections of our pie chart\n",
    "labels = AggregatedGenre['Genre']\n",
    "\n",
    "# The values of each section of the pie chart\n",
    "# sizes = Data_Influencers_DF.groupby([\"Genere\"],as_index=False).sum()[\"fare\"].tolist()\n",
    "sizes = AggregatedGenre['Followers']\n",
    "\n",
    "# The colors of each section of the pie chart\n",
    "colors = [\"gold\", \"lightskyblue\", \"lightcoral\",'red','pink','darkblue','purple']\n",
    "\n",
    "# Tells matplotlib to seperate the \"Python\" section from the others\n",
    "explode = (0,0,0,0,0,0,0.1)\n",
    "\n",
    "# Creates the pie chart based upon the values above\n",
    "# Automatically finds the percentages of each part of the pie chart\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct=\"%1.1f%%\", shadow=True, startangle=120)\n",
    "\n",
    "# Tells matplotlib that we want a pie chart with equal axes\n",
    "plt.axis(\"off\")\n",
    "\n",
    "  \n",
    "plt.title(\"% Followers per Genres\", fontsize=16)\n",
    "\n",
    "plt.savefig('Images/% Followers per Genres.png')\n",
    "# Prints our pie chart to the screen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## TM - whole cell\n",
    "# Labels for the sections of our pie chart\n",
    "labels = AggregatedGenre['Genre']\n",
    "\n",
    "# The values of each section of the pie chart\n",
    "# sizes = Data_Influencers_DF.groupby([\"Genere\"],as_index=False).sum()[\"fare\"].tolist()\n",
    "sizes = AggregatedGenre['Tweets']\n",
    "\n",
    "# The colors of each section of the pie chart\n",
    "colors = [\"gold\", \"lightskyblue\", \"lightcoral\",'red','pink','darkblue','purple']\n",
    "\n",
    "# Tells matplotlib to seperate the \"Python\" section from the others\n",
    "explode = (0,0,0,0,0,0,0.1)\n",
    "\n",
    "# Creates the pie chart based upon the values above\n",
    "# Automatically finds the percentages of each part of the pie chart\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct=\"%1.1f%%\", shadow=True, startangle=120)\n",
    "\n",
    "# Tells matplotlib that we want a pie chart with equal axes\n",
    "plt.axis(\"off\")\n",
    "\n",
    "  \n",
    "plt.title(\"% Tweets per Genres\", fontsize=16)\n",
    "\n",
    "plt.savefig('Images/% Tweets per Genres.png')\n",
    "# Prints our pie chart to the screen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -TM - People who are top ten Influencer who tweet more\n",
    "top_ten_twitters = Data_Influencers_DF.sort_values(['Tweets'],ascending=False).head(10)\n",
    "top_ten_twitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AggregatedGenre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -TM - Top ten Influencer who who have more Followers\n",
    "top_ten_influencer = Data_Influencers_DF.sort_values(['Followers'],ascending=False).head(10)\n",
    "top_ten_influencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--RR Still Working test cell\n",
    "# to find the handle of followers of the top most \n",
    "# active Influencer so that we can send the tweet through a bot.\n",
    "# top_ten_twitters.head(1)['Twitter_Handle'].map(lambda x: x.lstrip('@'))\n",
    "# import time\n",
    "# ids = []\n",
    "# for page in tweepy.Cursor(api.followers_ids, top_ten_twitters.head(1)['Twitter_Handle'].map(lambda x: x.lstrip('@'))).pages():\n",
    "#     ids.extend(page)\n",
    "#     time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sentiment Analysis of the Influencers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -TM - Extract the first 1000 tweets of the Influencers\n",
    "print(\"-----------Start extraction of the tweets posted by the Influencers!!!-----------\")\n",
    "Influencers = top_ten_influencer['Twitter_Handle']\n",
    "Sentiment_array = []\n",
    "\n",
    "for user in Influencers:\n",
    "    # Set the tweet count to 100\n",
    "    tweet_count = 1000\n",
    "    print(\"Extracting tweets from %s\"%user)\n",
    "    \n",
    "    # Extract tweets up to 5 pages\n",
    "    for x in range(10):\n",
    "        influencer_tweets = api.user_timeline(user,page = x)\n",
    "# influencer_tweets        \n",
    "        \n",
    "        # For each tweet in a bunch of public tweets\n",
    "        for tweet in influencer_tweets:\n",
    "            \n",
    "            #Calculate the compound, positive, negative and neutral values of each tweet\n",
    "            compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "            pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "            neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "            neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "            \n",
    "            age_of_tweet = (datetime.now(timezone.utc) - datetime.strptime(tweet['created_at'],'%a %b %d %H:%M:%S %z %Y')).days\n",
    "            tweetAge = 0 \n",
    "            if age_of_tweet < 180:\n",
    "                tweetAge = 1\n",
    "            elif age_of_tweet < 365:   \n",
    "                tweetAge = 2\n",
    "            else:\n",
    "                tweetAge = 3\n",
    "            \n",
    " \n",
    "            \n",
    "            # Save the Tweets in an array as a dictionery item \n",
    "            Sentiment_array.append({\"Influencers\" : user,\n",
    "                                    \"Tweet Text\" : tweet[\"text\"],\n",
    "                                    \"Compound\" : compound,\n",
    "                                    \"Positive\" : pos,\n",
    "                                    \"Negative\" : neg,\n",
    "                                    \"Neutral\" : neu,\n",
    "                                    \"Date\" : datetime.strptime(tweet[\"created_at\"],'%a %b %d %H:%M:%S %z %Y').strftime('%m/%d/%Y'),\n",
    "                                    \"AgeOfTweet\":age_of_tweet,\n",
    "                                    \"TweetAgeType\":tweetAge,\n",
    "                                    \"Tweets Ago\": tweet_count\n",
    "                                   })\n",
    "            \n",
    "            #Decrease count of tweet by 1 in the reverse order\n",
    "            tweet_count -= 1\n",
    "\n",
    "print(\"-----------End of Extraction of Tweets !!!-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RR Sentiment_array\n",
    "# Sentiment_array['TweetAge'] = 3\n",
    "\n",
    "# Sentiment_array.loc[Sentiment_array['AgeOfTweet'] < 180, 'TweetAge'] = 1\n",
    "# Sentiment_array.loc[Sentiment_array['AgeOfTweet'] > 180 & Sentiment_array['AgeOfTweet'] < 365, 'TweetAge'] = 2\n",
    "# Sentiment_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -TM - whole Cell\n",
    "# Create dataframe from the Dictionery item of the Sentiment Array\n",
    "Sentiment_DF = pd.DataFrame.from_dict(Sentiment_array)\n",
    "\n",
    "# -TM -Remove the '@' from the 'influence' column in the data frame\n",
    "Sentiment_DF[\"Influencers\"] = Sentiment_DF[\"Influencers\"].map(lambda x: x.lstrip('@'))\n",
    "\n",
    "# -TM - Re_arrang the columns and save into a CSV file\n",
    "Sentiment_DF = Sentiment_DF[[\"Influencers\", \"Date\", \"Tweet Text\"\n",
    "                             , \"Compound\", \"Positive\", \"Negative\"\n",
    "                             , \"Neutral\", \"Tweets Ago\",\"AgeOfTweet\",\"TweetAgeType\"\n",
    "                            ]]\n",
    "\n",
    "# -TM -Store output in a .CSV File\n",
    "Sentiment_DF.to_csv(\"OutPut/influencer_Sentiment_tweets_Analysis.csv\")\n",
    "\n",
    "Sentiment_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -TM -Get the unique list of the influencers\n",
    "Influencers_array = Sentiment_DF[\"Influencers\"].unique()\n",
    "Influencers_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -TM -Calculate the mean for each Influencers & store into a dataframe\n",
    "Influencers_Comp_Mean = Sentiment_DF.groupby(\"Influencers\").mean()[\"Compound\"].to_frame()\n",
    "\n",
    "#-TM -Reset the index \n",
    "Influencers_Comp_Mean.reset_index(inplace=True)\n",
    "\n",
    "Influencers_Comp_Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -TM - Whole cell\n",
    "# Set the values for x_axis & y_axis\n",
    "x_axis = Influencers_Comp_Mean.index.values\n",
    "y_axis = Influencers_Comp_Mean[\"Compound\"]\n",
    "X_Label = Influencers\n",
    "\n",
    "# Intialize the plots. \n",
    "fig,ax = plt.subplots()#  function that returns a tuple containing a figure and axes object(s)\n",
    "\n",
    "#Set the plot and assign the values like colors etc\n",
    "bars = ax.bar(x_axis,y_axis\n",
    "              , align = \"edge\"\n",
    "              , width = 1\n",
    "              , linewidth = 1\n",
    "              , edgecolor = 'black'\n",
    "              , color = [\"yellow\",\"lime\",\"red\",\"orange\",\"pink\"]\n",
    "             )\n",
    "\n",
    "# Set the tick(s) of the bar graph\n",
    "tick_locations = [value + 0.5 for value in range(len(x_axis))]\n",
    "plt.xticks(tick_locations,X_Label,rotation='vertical')\n",
    "\n",
    "# If value is positive then put True in the Summary else place False\n",
    "Influencers_Comp_Mean[\"Positive\"] = Influencers_Comp_Mean[\"Compound\"] > 0\n",
    "\n",
    "# Assign the height based on positive value after allocating True / false value\n",
    "height = Influencers_Comp_Mean.Positive.map({True: 0.03 , False: -0.03})\n",
    "\n",
    "# # Set the value on labels on the bars\n",
    "for bar in bars:\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + height[bars.index(bar)]\n",
    "            , round(Influencers_Comp_Mean[\"Compound\"][bars.index(bar)],3)\n",
    "            , ha = 'center'\n",
    "            , va = 'bottom'\n",
    "            )\n",
    "\n",
    "# Set the x_axis limits\n",
    "ax.set_xlim(0, len(x_axis))\n",
    "\n",
    "# Dynamically set the y_axis limits by finding the max & min value of y-axis\n",
    "ax.set_ylim(min(y_axis)-0.1, max(y_axis) + 0.1)\n",
    "\n",
    "# Set a horizontal line at y = 0\n",
    "plt.hlines(0,0,len(x_axis))\n",
    "\n",
    "# Title of the graph\n",
    "ax.set_title(\"Sentiments on Twitter of Influencers (%s)\" % (time.strftime(\"%x\")), fontsize=16)\n",
    "\n",
    "# Setting the y_axis label\n",
    "ax.set_ylabel(\"Polarity on Twitter \", fontsize=14)\n",
    "\n",
    "# # Setting the x_axis label\n",
    "ax.set_xlabel(\"The Influencers\", fontsize=14)\n",
    "  \n",
    "# Saving the graph\n",
    "plt.savefig(\"Images/The Influencer Twitter Sentiment.png\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IB People who are top 5 Influencer, with the greatest number of followers\n",
    "top_5_influencer = Data_Influencers_DF.sort_values(['Followers'],ascending=False).head(5)\n",
    "top_5_influencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IB Working Module --  Extract the first 100 tweets of the top ten Influencers\n",
    "\n",
    "# Extract the first 100 tweets of the Influencers\n",
    "print(\"-----------Start extraction of the tweets posted by the Influencers!!!-----------\")\n",
    "Influencers = []\n",
    "Influencers = top_5_influencer[\"Twitter_Handle\"]\n",
    "Influencers\n",
    "\n",
    "# IB Influencer's overall sentiments\n",
    "Influencers_overall_results = []\n",
    "\n",
    "Sentiment_array_infl = []\n",
    "\n",
    "# IB loop through each top ten influencer\n",
    "for user in Influencers:\n",
    "    \n",
    "   # IB Variables for holding compound sentiments\n",
    "    compound_list = []\n",
    "    \n",
    "    # IB Variable for max_id\n",
    "    oldest_tweet = None\n",
    "    \n",
    "    # Set the tweet count to 100\n",
    "    tweet_count = 0\n",
    "    print(\"Extracting tweets from %s\"%user)\n",
    "    \n",
    "    # Extract tweets up to 5 pages\n",
    "    for x in range(5):\n",
    "        ### IB - it is working - print(f\"For page number: '{x}' \")\n",
    "        influencer_tweets = api.user_timeline(user,page = x,  max_id = oldest_tweet )       \n",
    "        \n",
    "        # For each tweet in a bunch of public tweets\n",
    "        for tweet in influencer_tweets:\n",
    "            \n",
    "            #Calculate the compound, positive, negative and neutral values of each tweet\n",
    "            compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "            pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "            neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "            neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "            \n",
    "            # Save the Tweets in an array as a dictionery item \n",
    "            Sentiment_array_infl.append({\"Influencers\" : user,\n",
    "                                    \"Tweet Text\" : tweet[\"text\"],\n",
    "                                    \"Compound\" : compound,\n",
    "                                    \"Positive\" : pos,\n",
    "                                    \"Negative\" : neg,\n",
    "                                    \"Neutral\" : neu,\n",
    "                                    \"Date\" : tweet[\"created_at\"],\n",
    "                                    \"Tweets Ago\" : tweet_count\n",
    "                                   })\n",
    "            \n",
    "            # IB Collect compund sentiments for each Infuencer\n",
    "            compound_list.append(compound)\n",
    "            \n",
    "            #Decrease count of tweet by 1 in the reverse order\n",
    "            tweet_count += 1\n",
    "            \n",
    "        # IB get Tweet ID, subtract 1,assign to oldest_tweet\n",
    "        oldest_tweet = tweet[\"id\"] - 1\n",
    "        \n",
    "    # IB List for dictionary of results for _overall_ sentiments for each user\n",
    "    Influencers_overall_results.append({\"Influencer\": user, \"Overall Sentiment\": np.mean(compound_list)})\n",
    "\n",
    "print(\"-----------End of Extraction of Tweets !!!-----------\")\n",
    "###Influencers_overall_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IB Prepare Results Dataframe for the scatter plot\n",
    "Influencers_overall_results_df = pd.DataFrame.from_dict(Sentiment_array_infl)\n",
    "Influencers_overall_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IB Creating Sentiment Analysis for Top Ten Influences (07/02/2018) Scatter Plot\n",
    "\n",
    "# Separate media_user_results_df Dataset into 5 parts/ datasets by \"Media Source\"\n",
    "inf1_tweet_data_df = Influencers_overall_results_df[Influencers_overall_results_df['Influencers'] == \"@katyperry\"] \n",
    "inf2_tweet_data_df = Influencers_overall_results_df[Influencers_overall_results_df['Influencers'] == \"@BarackObama\"] \n",
    "# For each of media sources following the first one in the media dataset reset index to 0-99\n",
    "# in order to plot in the common area\n",
    "inf2_tweet_data_df = inf2_tweet_data_df.reset_index(drop=True)\n",
    "inf3_tweet_data_df = Influencers_overall_results_df[Influencers_overall_results_df['Influencers'] == \"@taylorswift13\"] \n",
    "inf3_tweet_data_df = inf3_tweet_data_df.reset_index(drop=True)\n",
    "inf4_tweet_data_df = Influencers_overall_results_df[Influencers_overall_results_df['Influencers'] == \"@ladygaga\"] \n",
    "inf4_tweet_data_df = inf4_tweet_data_df.reset_index(drop=True)\n",
    "inf5_tweet_data_df = Influencers_overall_results_df[Influencers_overall_results_df['Influencers'] == \"@TheEllenShow\"] \n",
    "inf5_tweet_data_df = inf5_tweet_data_df.reset_index(drop=True)\n",
    "\n",
    "# Get the values for each part of the scatter plot by \"Influencers\"\n",
    "# INF1\n",
    "# Get values for X axis\n",
    "inf1_tweet_ago_data = inf1_tweet_data_df.index\n",
    "# Get values for Y axis\n",
    "inf1_tweet_polarity_data = inf1_tweet_data_df[\"Compound\"] \n",
    "####################################################################\n",
    "# INF2\n",
    "# Get values for X axis\n",
    "inf2_tweet_ago_data = inf2_tweet_data_df.index \n",
    "# Get values for Y axis\n",
    "inf2_tweet_polarity_data = inf2_tweet_data_df[\"Compound\"] \n",
    "####################################################################\n",
    "# INF3\n",
    "# Get values for X axis\n",
    "inf3_tweet_ago_data = inf3_tweet_data_df.index\n",
    "# Get values for Y axis\n",
    "inf3_tweet_polarity_data = inf3_tweet_data_df[\"Compound\"] \n",
    "####################################################################\n",
    "# INF4\n",
    "# Get values for X axis\n",
    "inf4_tweet_ago_data = inf4_tweet_data_df.index\n",
    "# Get values for Y axis\n",
    "inf4_tweet_polarity_data = inf4_tweet_data_df[\"Compound\"] \n",
    "####################################################################\n",
    "# INF5\n",
    "# Get values for X axis\n",
    "inf5_tweet_ago_data = inf5_tweet_data_df.index\n",
    "# Get values for Y axis\n",
    "inf5_tweet_polarity_data = inf5_tweet_data_df[\"Compound\"] \n",
    "####################################################################\n",
    "\n",
    "# Organize the layout for the scatter plot\n",
    "plt.title(\"Sentimental Analysis of Top 5 Influencers 100 Tweets(07/03/2018)\", Fontsize= 10 )\n",
    "# Labels for the scatter plot circles for each Influencer\n",
    "labels = [\"KatyPerry\" \"BarackObama\" \"TaylorSwift\" \"LadyGaga\" \"TheEllenShow\"]\n",
    "# Colors for the scatter plot circles for each Influencer\n",
    "colors = [\"lightskyblue\",\"green\",\"red\", \"blue\", \"gold\"]\n",
    "\n",
    "# Define X and Y of the scatter plot\n",
    "plt.xlabel(\"Tweets Ago\")\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "\n",
    "# Define X and Y limits\n",
    "plt.xlim(100, 0)\n",
    "plt.ylim( -1.0, 1.0 )\n",
    "\n",
    "# Writing data to the same Scatter Plot 5 times, for each Influencer \n",
    "#           (\"KatyPerry\" \"BarackObama\" \"TaylorSwift\" \"LadyGaga\" \"TheEllenShow\")\n",
    "plt.scatter( inf1_tweet_ago_data, inf1_tweet_polarity_data, c=\"lightskyblue\", edgecolor=\"black\", \n",
    "            linewidths=1, alpha =0.75, marker='o', label=\"KatyPerry\")\n",
    "plt.scatter( inf2_tweet_ago_data, inf2_tweet_polarity_data, c=\"green\", edgecolor=\"black\", \\\n",
    "            linewidths=1, alpha=0.75, marker='o', label=\"BarackObama\")\n",
    "plt.scatter( inf3_tweet_ago_data, inf3_tweet_polarity_data, c=\"red\", edgecolor=\"black\", \n",
    "            linewidths=1, alpha=0.75, marker='o', label=\"TaylorSwift\")\n",
    "plt.scatter( inf4_tweet_ago_data, inf4_tweet_polarity_data, c=\"blue\", edgecolor=\"black\", \n",
    "            linewidths=1, alpha=0.75, marker='o', label=\"LadyGaga\")\n",
    "plt.scatter( inf5_tweet_ago_data, inf5_tweet_polarity_data, c=\"gold\", edgecolor=\"black\", \n",
    "            linewidths=1, alpha=0.75, marker='o', label=\"TheEllenShow\")\n",
    " \n",
    "# Create the legend of the Scatter plot\n",
    "legend = plt.legend(fontsize=\"small\", loc=\"center left\", title=\"Top 5 Influencers\", bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure with the Scatter Plot\n",
    "plt.savefig(\"OutPut/InfluencersSentimentsTweeterPolarityScatterPlot.png\")\n",
    "\n",
    "# Show the Scatter Plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IB Top 5 People who who have more Followers\n",
    "top_5_twitters = Data_Influencers_DF.sort_values(['Tweets'],ascending=False).head(5)\n",
    "top_5_twitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IB Working Module --  Extract the first 100 tweets of the top Twitters\n",
    "\n",
    "# # Extract the first 100 tweets of the Influencers\n",
    "print(\"-----------Start extraction of the tweets posted by the Influencers!!!-----------\")\n",
    "Twitters = []\n",
    "Twitters = top_5_twitters[\"Twitter_Handle\"]\n",
    "Twitters\n",
    "\n",
    "# IB Twitters's overall sentiments\n",
    "Twitters_overall_results = []\n",
    "\n",
    "Sentiment_array_tw = []\n",
    "\n",
    "# IB loop through each top ten twitter\n",
    "for user in Twitters:\n",
    "    \n",
    "    ###print(f\"For Twitter: '{user}' \")\n",
    "    # IB Variables for holding compound sentiments\n",
    "    compound_list_tw = []\n",
    "    \n",
    "    # IB Variable for max_id\n",
    "    oldest_tweet = None\n",
    "    \n",
    "    # Set the tweet count to 100\n",
    "    tweet_count = 0\n",
    "    print(\"Extracting tweets from %s\"%user)\n",
    "    \n",
    "    # Extract tweets up to 5 pages\n",
    "    for x in range(5):\n",
    "        \n",
    "        ### IB - it is working - print(f\"For page number: '{x}' \")\n",
    "        twitters_tweets = api.user_timeline(user,page = x,  max_id = oldest_tweet )       \n",
    "        \n",
    "        # For each tweet in a bunch of public tweets\n",
    "        for tweet in twitters_tweets:\n",
    "            \n",
    "            #Calculate the compound, positive, negative and neutral values of each tweet\n",
    "            compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "            pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "            neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "            neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "            \n",
    "            # Save the Tweets in an array as a dictionery item \n",
    "            Sentiment_array_tw.append({\"Twitter\" : user,\n",
    "                                    \"Tweet Text\" : tweet[\"text\"],\n",
    "                                    \"Compound\" : compound,\n",
    "                                    \"Positive\" : pos,\n",
    "                                    \"Negative\" : neg,\n",
    "                                    \"Neutral\" : neu,\n",
    "                                    \"Date\" : tweet[\"created_at\"],\n",
    "                                    \"Tweets Ago\" : tweet_count\n",
    "                                   })\n",
    "            \n",
    "            # IB Collect compund sentiments for each Infuencer\n",
    "            compound_list_tw.append(compound)\n",
    "            \n",
    "            #Decrease count of tweet by 1 in the reverse order\n",
    "            tweet_count += 1\n",
    "            \n",
    "        # IB get Tweet ID, subtract 1,assign to oldest_tweet\n",
    "        oldest_tweet = tweet[\"id\"] - 1\n",
    "        \n",
    "    # IB List for dictionary of results for _overall_ sentiments for each user\n",
    "    Twitters_overall_results.append({\"Twitter\": user, \"Overall Sentiment\": np.mean(compound_list_tw)})\n",
    "\n",
    "print(\"-----------End of Extraction of Tweets !!!-----------\")\n",
    "###Twitters_overall_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IB Prepare Results Dataframe for the scatter plot\n",
    "Twitters_overall_results_df = pd.DataFrame.from_dict(Sentiment_array_tw)\n",
    "Twitters_overall_results_df.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IB Creating Sentiment Analysis for Top Ten Influences Scatter Plot\n",
    "\n",
    "# Separate media_user_results_df Dataset into 5 parts/ datasets by \"Media Source\"\n",
    "tw1_tweet_data_df = Twitters_overall_results_df[Twitters_overall_results_df['Twitter'] == \"@Noahpinion\"] \n",
    "tw2_tweet_data_df = Twitters_overall_results_df[Twitters_overall_results_df['Twitter'] == \"@BDUTT\"] \n",
    "# For each of media sources following the first one in the media dataset reset index to 0-99\n",
    "# in order to plot in the common area\n",
    "tw2_tweet_data_df = tw2_tweet_data_df.reset_index(drop=True)\n",
    "tw3_tweet_data_df = Twitters_overall_results_df[Twitters_overall_results_df['Twitter'] == \"@ProfessorChic\"] \n",
    "tw3_tweet_data_df = tw3_tweet_data_df.reset_index(drop=True)\n",
    "tw4_tweet_data_df = Twitters_overall_results_df[Twitters_overall_results_df['Twitter'] == \"@haroldpollack\"] \n",
    "tw4_tweet_data_df = tw4_tweet_data_df.reset_index(drop=True)\n",
    "tw5_tweet_data_df = Twitters_overall_results_df[Twitters_overall_results_df['Twitter'] == \"@CoryBooker\"] \n",
    "tw5_tweet_data_df = tw5_tweet_data_df.reset_index(drop=True)\n",
    "\n",
    "# Get the values for each part of the scatter plot by \"Twitter\"\n",
    "# TW1\n",
    "# Get values for X axis\n",
    "tw1_tweet_ago_data = tw1_tweet_data_df.index\n",
    "# Get values for Y axis\n",
    "tw1_tweet_polarity_data = tw1_tweet_data_df[\"Compound\"] \n",
    "####################################################################\n",
    "# TW2\n",
    "# Get values for X axis\n",
    "tw2_tweet_ago_data = tw2_tweet_data_df.index \n",
    "# Get values for Y axis\n",
    "tw2_tweet_polarity_data = tw2_tweet_data_df[\"Compound\"] \n",
    "####################################################################\n",
    "# TW3\n",
    "# Get values for X axis\n",
    "tw3_tweet_ago_data = tw3_tweet_data_df.index\n",
    "# Get values for Y axis\n",
    "tw3_tweet_polarity_data = tw3_tweet_data_df[\"Compound\"] \n",
    "####################################################################\n",
    "# TW4\n",
    "# Get values for X axis\n",
    "tw4_tweet_ago_data = tw4_tweet_data_df.index\n",
    "# Get values for Y axis\n",
    "tw4_tweet_polarity_data = tw4_tweet_data_df[\"Compound\"] \n",
    "####################################################################\n",
    "# TW5\n",
    "# Get values for X axis\n",
    "tw5_tweet_ago_data = tw5_tweet_data_df.index\n",
    "# Get values for Y axis\n",
    "tw5_tweet_polarity_data = tw5_tweet_data_df[\"Compound\"] \n",
    "###################################################################\n",
    "\n",
    "# Organize the layout for the scatter plot\n",
    "plt.title(\"Sentimental Analysis of Top 5 Tweeters Tweets(07/03/2018)\", Fontsize= 10 )\n",
    "\n",
    "# Labels for the scatter plot circles for each Twitter\n",
    "labels = [\"Noahpinion\" \"BDUTT\" \"ProfessorChic\" \"HaroldPollack\" \"CoryBooker\"]\n",
    "# Colors for the scatter plot circles for each Twitter\n",
    "colors = [\"lightskyblue\",\"green\",\"red\", \"blue\", \"gold\"]\n",
    "\n",
    "# Define X and Y of the scatter plot\n",
    "plt.xlabel(\"Tweets Ago\")\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "\n",
    "# Define X and Y limits\n",
    "plt.xlim(100, 0)\n",
    "plt.ylim( -1.0, 1.0 )\n",
    "\n",
    "# Writing data to the same Scatter Plot 5 times, for each Twitter \n",
    "#           ( \"Noahpinion\" \"BDUTT\" \"ProfessorChic\" \"HaroldPollack\" \"CoryBooker\")\n",
    "plt.scatter( tw1_tweet_ago_data, tw1_tweet_polarity_data, c=\"lightskyblue\", edgecolor=\"black\", \n",
    "            linewidths=1, alpha =0.75, marker='o', label=\"Noahpinion\")\n",
    "plt.scatter( tw2_tweet_ago_data, tw2_tweet_polarity_data, c=\"green\", edgecolor=\"black\", \\\n",
    "            linewidths=1, alpha=0.75, marker='o', label=\"BDUTT\")\n",
    "plt.scatter( tw3_tweet_ago_data, tw3_tweet_polarity_data, c=\"red\", edgecolor=\"black\", \n",
    "            linewidths=1, alpha=0.75, marker='o', label=\"ProfessorChic\")\n",
    "plt.scatter( tw4_tweet_ago_data, tw4_tweet_polarity_data, c=\"blue\", edgecolor=\"black\", \n",
    "            linewidths=1, alpha=0.75, marker='o', label=\"HaroldPollack\")\n",
    "plt.scatter( tw5_tweet_ago_data, tw5_tweet_polarity_data, c=\"gold\", edgecolor=\"black\", \n",
    "            linewidths=1, alpha=0.75, marker='o', label=\"CoryBooker\")\n",
    " \n",
    "# Create the legend of the Scatter plot\n",
    "legend = plt.legend(fontsize=\"small\", loc=\"center left\", title=\"Top 5 Influencers\", bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure with the Scatter Plot\n",
    "plt.savefig(\"OutPut/TweetersSentimentsTweeterPolarityScatterPlot.png\")\n",
    "\n",
    "# Show the Scatter Plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP\n",
    "# influencersDictionary = {}\n",
    "# colors = [\"yellow\",\"lime\",\"red\",\"orange\",\"pink\",\"yellow\",\"lime\",\"red\",\"orange\",\"pink\"]\n",
    "# index = 0\n",
    "# for person in Influencers:\n",
    "#     influencersDictionary[person] = colors[index]\n",
    "#     index+=1\n",
    "# influencersDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an array of Influencers Houses with the unique function in the data frame\n",
    "# Influencers_array = Sentiment_DF[\"Influencers\"].unique()\n",
    "# Influencers_array\n",
    "\n",
    "# # #Plotting the graph for each influencer\n",
    "# for influencer in Influencers_array:\n",
    "# # Creating a temporary data frame to store for only one influencer at a time\n",
    "#         Temp_DF = Sentiment_DF[Sentiment_DF[\"influencer\"] == influencer]\n",
    "        \n",
    "#         Sentiment_DF['influencer'] = Sentiment_DF['influencer'].map(lambda x: x.lstrip('@'))\n",
    "# #Temp_DF\n",
    "    \n",
    "#         plt.scatter(Temp_DF[\"Tweets Ago\"],Temp_DF[\"Compound\"]\n",
    "#                  , marker = \"o\", linewidth = 0, alpha = 0.8, label = Influencers\n",
    "#                  , facecolors = Temp_DF.influencer.map(influencersDictionary)\n",
    "#                 )\n",
    "\n",
    "# # # Set the legend \n",
    "# plt.legend(bbox_to_anchor = (1,1), title=\"The Influencers\", loc='best')\n",
    "\n",
    "# # # Set the labels of x_axis, y_axis & title \n",
    "# plt.xlabel(\"Tweets Ago\", fontsize=12)\n",
    "# plt.ylabel(\"Tweet Polarity\", fontsize=12)\n",
    "# plt.title(\"Sentiment Analysis of The Influencers Tweets (%s)\" % (time.strftime(\"%x\")), fontsize=16)\n",
    "\n",
    "# # #Set the limite of  x_axis and y_axis\n",
    "# plt.xlim(0, 101)\n",
    "# plt.ylim(-1,1)\n",
    "\n",
    "# # # Set the grid\n",
    "# plt.grid(True)\n",
    "\n",
    "# filePath = 'Images'\n",
    "# if not path.exists(filePath):\n",
    "#     makedirs(filePath)\n",
    "\n",
    "# # Save the result to a .png file\n",
    "# plt.savefig(\"Sentiment Analysis of Influencers Tweets.png\",bbox_inches='tight')\n",
    "# # plt.savefig(\"Sentiment Analysis of The influencer's Tweets.png\",bbox_inches='tight')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version: 2.0\n",
    "# Date: Mon July 2nd, 2018 \n",
    "# Time: 10:25 PM\n",
    "\n",
    "# Functionalities: \n",
    "# A) Data Analysis\n",
    "#     1. Created dataframe.\n",
    "#     2. Sorting\n",
    "# B) Sentiment Analysis\n",
    "\n",
    "# WIP (Work in progress)\n",
    "# 1. Tweet bot. The git part is done. \n",
    "# Automation is pending as hosting might need neet tech which we have not covered now.\n",
    "\n",
    "# Pending items:\n",
    "# 1. Data Cleaning\n",
    "# 2. Graphs and plots\n",
    "# 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version: 3.0 - IB\n",
    "# Date: Monday 7/3/2018\n",
    "# Time: 3:00 PM\n",
    "# Functionalities: \n",
    "# A) Overcame _TweepError - 34_ by using max_id logic while calling api.user_timeline Tweepy function\n",
    "#    Sentiment Analysis for Top 5 Influencers and Top 5 Twitters function \n",
    "# B) Created the Scatter Plot for Sentimental Analysis of Top 5 Influencers last 100 tweets\n",
    "# C) Created the Scatter Plot for Sentimental Analysis of Top 5 Twitters last 100 tweets\n",
    "#    Scatter Plots png files are saved in OutPut directory\n",
    "#\n",
    "# These Scatter Plots visualize a great difference between _overal_ ratings of Influencers and People who tweet most\n",
    "# \n",
    "# For Merging: Code has # IB comments, 8 cells. When \"Restart and Run All\" Kernel, my code is in ln[37] to ln[44]\n",
    "# With amount of tweets we have it runs under 10 minutes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
